import os
import cPickle as pickle
import sys
import re


class Spam_Filter():

	data = {
		'spam':{},
		'ham':{},
		'probs':{},
		'num_spam': 0,
		'num_ham': 0
	}

	pattern = re.compile(r"[^A-Za-z\-'\$]+")


	"""
	Loads data about token meta data from file. Note: it must have been generated by previously running build_dicts
	"""
	def load_dicts(self):
		f = open('data.pkl', 'rb')
		self.data = pickle.load(f)
		f.close()

	"""
	Takes a string and returns a list of tokens 
	"""
	def tokenizer(self, str):
		return self.pattern.split(str)

	"""
	Takes an array of tokens and adds these token to a running tally of their frequencys
	"""
	def count_tokens(self, email_type, tokens):
		d = self.data[email_type]
		for token in tokens:
			#skip if token is just digits
			if token.isdigit():
				continue

			token = token.lower()
			if token in d:
				d[token] += 1
			else:
				d[token] = 1

	"""
	Takes a type of email to creates a frequency hash
	"""
	def read_emails(self, email_type):
		path = email_type + '/'
		
		emails = os.listdir(path)

		self.data['num_'+email_type] = len(emails)

		for email in emails:
			f = open(path+email)

			content = ""
			for line in f.xreadlines():
				content += line

			tokens = self.tokenizer(content)
			self.count_tokens(email_type, tokens)

	"""
	Creates a hash the maps a token to the probility that a email is spam given it contains that token
	"""
	def calc_probs(self):
		union = dict(self.data['spam'].items() + self.data['ham'].items())
		for token in union:
			good = self.data['ham'].get(token, 0) * 2
			bad = self.data['spam'].get(token, 0)

			val = 0
			if good + bad >= 5:
				if good > 0 and bad == 0:
					val = .01
				if bad > 0 and good == 0:
					val = .99

				bad_ratio = float(bad)/self.data['num_spam']
				good_ratio = float(good)/self.data['num_ham']
				val = bad_ratio/(bad_ratio+good_ratio)

			if val != 0:
				self.data['probs'][token] = val

	"""
	Creates the necessary dictionary for spam filter to work and saves these dictionaries to a file for later use
	"""				
	def build_dicts(self):
		self.read_emails('spam')
		self.read_emails('ham')
		self.calc_probs()

		f = open('data.pkl', 'wb')
		pickle.dump(self.data, f)
		f.close()

	"""
	Take the text of an email and returns the probabilty it is spam
	"""
	def judge_email(self, str):
		tokens = self.tokenizer(str)
		dedup_tokens = list(set(tokens)) # condense to only unique tokens
		top = sorted(dedup_tokens, key = lambda x : -self.data['probs'].get(x, 0))[:15] # 15 highest prob tokens

		probs = []
		for token in top:
			val = self.data['probs'].get(token, .4)
			probs.append(val)

		
		isSpam = 1
		notSpam = 1
		for prob in probs:
			print prob
			isSpam *= prob
			notSpam *= (1-prob)
		return isSpam/(isSpam+notSpam)


def test():
	f = open(sys.argv[1])

	s = ""
	for line in f.xreadlines():
		s += line

	f = Spam_Filter()
	f.load_dicts()
	return f.judge_email(s)

print test()
