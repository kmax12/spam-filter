import os
import cPickle as pickle
import sys
import re


class SpamFilter():
	TOKEN_PATTERN = re.compile(r"[^A-Za-z\-'\$]+")

	def __init__ (self, load=None):
		self.data = {
			'spam':{},
			'ham':{},
			'probs':{},
			'num_spam': 0,
			'num_ham': 0
		}

		if load:
			self.load_dicts(load)
		else:
			self.build_dicts()


	def load_dicts(self, file_name):
		"""
		Loads data about token meta data from file. Note: it must have been generated by previously running build_dicts
		"""
		f = open(file_name, 'rb')
		self.data = pickle.load(f)
		f.close()


	def tokenizer(self, str):
		"""
		Takes a string and returns a list of lowercase tokens
		"""
		tokens = self.TOKEN_PATTERN.split(str)
		return [token.lower() for token in tokens]


	def count_tokens(self, email_type, tokens):
		"""
		Takes an array of tokens and adds these token to a running tally of their frequencys
		"""
		d = self.data[email_type]
		for token in tokens:
			#skip if token is just digits
			if token.isdigit():
				continue

			d[token] = d.get(token, 0) + 1


	def read_emails(self, email_type):
		"""
		Creates the necessary dictionary for spam filter to work and saves these dictionaries to a file for later use
		"""		
		path = email_type + '/'
		
		emails = os.listdir(path)

		self.data['num_'+email_type] = len(emails)

		for email in emails:
			f = open(path+email)

			content = f.read()

			tokens = self.tokenizer(content)
			self.count_tokens(email_type, tokens)

			f.close()

	def calc_probs(self):
		"""
		Creates a hash the maps a token to the probility that a email is spam given it contains that token
		"""
		union = dict(self.data['spam'].items() + self.data['ham'].items())
		for token in union:
			good = self.data['ham'].get(token, 0) * 2
			bad = self.data['spam'].get(token, 0)

			val = 0
			if good + bad >= 5:
				if good > 0 and bad == 0:
					val = .01
				if bad > 0 and good == 0:
					val = .99

				bad_ratio = float(bad)/self.data['num_spam']
				good_ratio = float(good)/self.data['num_ham']
				val = bad_ratio/(bad_ratio+good_ratio)

			if val != 0:
				self.data['probs'][token] = val

		
	def build_dicts(self):
		"""
		Creates the necessary dictionary for spam filter to work and saves these dictionaries to a file for later use
		"""		
		self.read_emails('spam')
		self.read_emails('ham')
		self.calc_probs()

		f = open('data.pkl', 'wb')
		pickle.dump(self.data, f)
		f.close()

	def judge_email(self, str):
		"""
		Take the text of an email and returns the probabilty it is spam
		"""
		tokens = self.tokenizer(str)
		dedup_tokens = list(set(tokens)) # condense to only unique tokens
		top = sorted(dedup_tokens, key = lambda x : -abs(self.data['probs'].get(x, .4)-.5))[:15] # 15 most interesting tokens

		probs = []
		for token in top:
			val = self.data['probs'].get(token, .4)
			probs.append(val)

		
		isSpam = 1
		isNotSpam = 1
		for prob in probs:
			isSpam *= prob
			isNotSpam *= (1-prob)
		return isSpam/(isSpam+isNotSpam)


def test():
	f = open(sys.argv[1])

	s = f.read()

	f = SpamFilter('data.pkl')

	return f.judge_email(s)

print test()
